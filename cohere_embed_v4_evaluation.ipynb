{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Bedrock Cohere Embed v4 Model Evaluation\n",
    "## Testing Text, Image, and Multimodal Embeddings in SageMaker\n",
    "\n",
    "This notebook demonstrates how to use AWS Bedrock's Cohere Embed v4 model for:\n",
    "- Text embeddings\n",
    "- Image embeddings\n",
    "- Text + Image (multimodal) embeddings\n",
    "\n",
    "**Model ID**: `cohere.embed-english-v3` or `cohere.embed-multilingual-v3`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install boto3 botocore pillow numpy matplotlib -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Union\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure AWS Bedrock Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AWS Bedrock client initialized for region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "# Configure AWS credentials and region\n",
    "# Make sure you have configured AWS credentials using:\n",
    "# aws configure\n",
    "# Or set environment variables: AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY\n",
    "\n",
    "AWS_REGION = 'us-east-1'  # Change to your preferred region\n",
    "\n",
    "# Initialize Bedrock client\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name=AWS_REGION\n",
    ")\n",
    "\n",
    "print(f\"âœ… AWS Bedrock client initialized for region: {AWS_REGION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Helper functions defined successfully\n"
     ]
    }
   ],
   "source": [
    "def get_cohere_embeddings(\n",
    "    texts: List[str],\n",
    "    input_type: str = \"search_document\",\n",
    "    embedding_types: List[str] = [\"float\"],\n",
    "    model_id: str = \"cohere.embed-v4:0\"\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Generate embeddings using Cohere Embed model on AWS Bedrock\n",
    "    \n",
    "    Args:\n",
    "        texts: List of text strings to embed\n",
    "        input_type: Type of input - \"search_document\", \"search_query\", \"classification\", \"clustering\"\n",
    "        embedding_types: List of embedding types - [\"float\", \"int8\", \"uint8\", \"binary\", \"ubinary\"]\n",
    "        model_id: Bedrock model ID for Cohere\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing embeddings and metadata\n",
    "    \"\"\"\n",
    "    body = json.dumps({\n",
    "        \"texts\": texts,\n",
    "        \"input_type\": input_type,\n",
    "        \"embedding_types\": embedding_types,\n",
    "        \"truncate\": \"END\"  # Options: \"NONE\", \"START\", \"END\"\n",
    "    })\n",
    "    \n",
    "    try:\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId=model_id,\n",
    "            body=body,\n",
    "            contentType='application/json',\n",
    "            accept='application/json'\n",
    "        )\n",
    "        \n",
    "        response_body = json.loads(response['body'].read())\n",
    "        return response_body\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error generating embeddings: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def image_to_base64(image_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert image file to base64 string\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "    \n",
    "    Returns:\n",
    "        Base64 encoded string of the image\n",
    "    \"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "def calculate_similarity(embedding1: List[float], embedding2: List[float]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity between two embeddings\n",
    "    \n",
    "    Args:\n",
    "        embedding1: First embedding vector\n",
    "        embedding2: Second embedding vector\n",
    "    \n",
    "    Returns:\n",
    "        Cosine similarity score\n",
    "    \"\"\"\n",
    "    vec1 = np.array(embedding1)\n",
    "    vec2 = np.array(embedding2)\n",
    "    \n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "\n",
    "def visualize_embeddings(embeddings: List[List[float]], labels: List[str]):\n",
    "    \"\"\"\n",
    "    Visualize embeddings using PCA for dimensionality reduction\n",
    "    \n",
    "    Args:\n",
    "        embeddings: List of embedding vectors\n",
    "        labels: Labels for each embedding\n",
    "    \"\"\"\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    # Reduce to 2D for visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    embeddings_2d = pca.fit_transform(embeddings)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, label in enumerate(labels):\n",
    "        plt.scatter(embeddings_2d[i, 0], embeddings_2d[i, 1], s=100)\n",
    "        plt.annotate(label, (embeddings_2d[i, 0], embeddings_2d[i, 1]), \n",
    "                    fontsize=9, alpha=0.8)\n",
    "    \n",
    "    plt.title('Embedding Visualization (PCA)')\n",
    "    plt.xlabel('First Principal Component')\n",
    "    plt.ylabel('Second Principal Component')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"âœ… Helper functions defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Text Embeddings\n",
    "\n",
    "Testing various text embedding scenarios:\n",
    "- Single text embedding\n",
    "- Batch text embeddings\n",
    "- Semantic similarity calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 1: Single Text Embedding\n",
      "================================================================================\n",
      "\n",
      "âœ… Successfully generated embedding\n",
      "ğŸ“Š Embedding dimension: 1536\n",
      "ğŸ“ Text: Artificial Intelligence is transforming the healthcare industry.\n",
      "ğŸ”¢ First 10 values: [0.02493202, 0.021231173, -0.026100706, -0.034281526, 0.005380836, -0.028438084, -0.032918055, -0.014511214, -0.004723449, 0.029996336]\n",
      "ğŸ“ˆ Embedding stats:\n",
      "   - Min value: -0.0853\n",
      "   - Max value: 0.1293\n",
      "   - Mean value: 0.0003\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Single Text Embedding\n",
    "print(\"=\" * 80)\n",
    "print(\"TEST 1: Single Text Embedding\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "single_text = [\"Artificial Intelligence is transforming the healthcare industry.\"]\n",
    "\n",
    "result = get_cohere_embeddings(\n",
    "    texts=single_text,\n",
    "    input_type=\"search_document\",\n",
    "    embedding_types=[\"float\"]\n",
    ")\n",
    "\n",
    "if result:\n",
    "    embeddings = result['embeddings']['float']\n",
    "    print(f\"\\nâœ… Successfully generated embedding\")\n",
    "    print(f\"ğŸ“Š Embedding dimension: {len(embeddings[0])}\")\n",
    "    print(f\"ğŸ“ Text: {single_text[0]}\")\n",
    "    print(f\"ğŸ”¢ First 10 values: {embeddings[0][:10]}\")\n",
    "    print(f\"ğŸ“ˆ Embedding stats:\")\n",
    "    print(f\"   - Min value: {min(embeddings[0]):.4f}\")\n",
    "    print(f\"   - Max value: {max(embeddings[0]):.4f}\")\n",
    "    print(f\"   - Mean value: {np.mean(embeddings[0]):.4f}\")\n",
    "else:\n",
    "    print(\"âŒ Failed to generate embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST 2: Batch Text Embeddings & Semantic Similarity\n",
      "================================================================================\n",
      "\n",
      "âœ… Successfully generated 5 embeddings\n",
      "ğŸ“Š Embedding dimension: 1536\n",
      "\n",
      "ğŸ“Š Similarity Matrix:\n",
      "\n",
      "Text pairs and their similarity scores:\n",
      "--------------------------------------------------------------------------------\n",
      "Text 1 â†” Text 2: 0.5241\n",
      "  [Machine learning models can predict customer behav...]\n",
      "  [Deep learning algorithms are used for image recogn...]\n",
      "\n",
      "Text 1 â†” Text 3: 0.4297\n",
      "  [Machine learning models can predict customer behav...]\n",
      "  [Natural language processing helps computers unders...]\n",
      "\n",
      "Text 1 â†” Text 4: 0.3115\n",
      "  [Machine learning models can predict customer behav...]\n",
      "  [The cat sat on the mat....]\n",
      "\n",
      "Text 1 â†” Text 5: 0.5110\n",
      "  [Machine learning models can predict customer behav...]\n",
      "  [Neural networks are inspired by the human brain....]\n",
      "\n",
      "Text 2 â†” Text 3: 0.5580\n",
      "  [Deep learning algorithms are used for image recogn...]\n",
      "  [Natural language processing helps computers unders...]\n",
      "\n",
      "Text 2 â†” Text 4: 0.3155\n",
      "  [Deep learning algorithms are used for image recogn...]\n",
      "  [The cat sat on the mat....]\n",
      "\n",
      "Text 2 â†” Text 5: 0.6280\n",
      "  [Deep learning algorithms are used for image recogn...]\n",
      "  [Neural networks are inspired by the human brain....]\n",
      "\n",
      "Text 3 â†” Text 4: 0.3223\n",
      "  [Natural language processing helps computers unders...]\n",
      "  [The cat sat on the mat....]\n",
      "\n",
      "Text 3 â†” Text 5: 0.5851\n",
      "  [Natural language processing helps computers unders...]\n",
      "  [Neural networks are inspired by the human brain....]\n",
      "\n",
      "Text 4 â†” Text 5: 0.3132\n",
      "  [The cat sat on the mat....]\n",
      "  [Neural networks are inspired by the human brain....]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Batch Text Embeddings with Semantic Similarity\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEST 2: Batch Text Embeddings & Semantic Similarity\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_texts = [\n",
    "    \"Machine learning models can predict customer behavior.\",\n",
    "    \"Deep learning algorithms are used for image recognition.\",\n",
    "    \"Natural language processing helps computers understand human language.\",\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"Neural networks are inspired by the human brain.\"\n",
    "]\n",
    "\n",
    "result = get_cohere_embeddings(\n",
    "    texts=test_texts,\n",
    "    input_type=\"clustering\",\n",
    "    embedding_types=[\"float\"]\n",
    ")\n",
    "\n",
    "if result:\n",
    "    embeddings = result['embeddings']['float']\n",
    "    print(f\"\\nâœ… Successfully generated {len(embeddings)} embeddings\")\n",
    "    print(f\"ğŸ“Š Embedding dimension: {len(embeddings[0])}\")\n",
    "    \n",
    "    # Calculate similarity matrix\n",
    "    print(\"\\nğŸ“Š Similarity Matrix:\")\n",
    "    print(\"\\nText pairs and their similarity scores:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i in range(len(test_texts)):\n",
    "        for j in range(i + 1, len(test_texts)):\n",
    "            similarity = calculate_similarity(embeddings[i], embeddings[j])\n",
    "            print(f\"Text {i+1} â†” Text {j+1}: {similarity:.4f}\")\n",
    "            print(f\"  [{test_texts[i][:50]}...]\")\n",
    "            print(f\"  [{test_texts[j][:50]}...]\\n\")\n",
    "else:\n",
    "    print(\"âŒ Failed to generate embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST 3: Testing Different Input Types\n",
      "================================================================================\n",
      "\n",
      "ğŸ” Query-Document Similarity Scores:\n",
      "\n",
      "Query: What are the applications of AI in healthcare?\n",
      "\n",
      "Ranked documents by relevance:\n",
      "\n",
      "1. Score: 0.4537\n",
      "   Document 1: AI helps in early disease detection through medical imaging analysis.\n",
      "\n",
      "2. Score: 0.2944\n",
      "   Document 2: Machine learning models predict patient outcomes and treatment responses.\n",
      "\n",
      "3. Score: 0.1388\n",
      "   Document 3: The weather is beautiful today.\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Different Input Types\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEST 3: Testing Different Input Types\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "query_text = [\"What are the applications of AI in healthcare?\"]\n",
    "document_texts = [\n",
    "    \"AI helps in early disease detection through medical imaging analysis.\",\n",
    "    \"Machine learning models predict patient outcomes and treatment responses.\",\n",
    "    \"The weather is beautiful today.\"\n",
    "]\n",
    "\n",
    "# Get query embedding\n",
    "query_result = get_cohere_embeddings(\n",
    "    texts=query_text,\n",
    "    input_type=\"search_query\",\n",
    "    embedding_types=[\"float\"]\n",
    ")\n",
    "\n",
    "# Get document embeddings\n",
    "doc_result = get_cohere_embeddings(\n",
    "    texts=document_texts,\n",
    "    input_type=\"search_document\",\n",
    "    embedding_types=[\"float\"]\n",
    ")\n",
    "\n",
    "if query_result and doc_result:\n",
    "    query_embedding = query_result['embeddings']['float'][0]\n",
    "    doc_embeddings = doc_result['embeddings']['float']\n",
    "    \n",
    "    print(\"\\nğŸ” Query-Document Similarity Scores:\")\n",
    "    print(f\"\\nQuery: {query_text[0]}\\n\")\n",
    "    \n",
    "    similarities = []\n",
    "    for i, doc in enumerate(document_texts):\n",
    "        similarity = calculate_similarity(query_embedding, doc_embeddings[i])\n",
    "        similarities.append((i, similarity, doc))\n",
    "    \n",
    "    # Sort by similarity\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"Ranked documents by relevance:\")\n",
    "    for rank, (idx, score, doc) in enumerate(similarities, 1):\n",
    "        print(f\"\\n{rank}. Score: {score:.4f}\")\n",
    "        print(f\"   Document {idx + 1}: {doc}\")\n",
    "else:\n",
    "    print(\"âŒ Failed to generate embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST 4: Testing Different Embedding Types\n",
      "================================================================================\n",
      "\n",
      "âœ… Successfully generated embeddings in multiple formats\n",
      "ğŸ“ Text: Cloud computing enables scalable and flexible IT infrastructure.\n",
      "\n",
      "\n",
      "FLOAT Embedding:\n",
      "  - Dimension: 1536\n",
      "  - First 10 values: [0.024234222, 0.01692549, -0.044237074, -0.025580568, 0.0023320632, -0.004928587, -0.033081636, -0.0013102829, 0.048660778, 0.04154438]\n",
      "  - Data type: <class 'float'>\n",
      "\n",
      "INT8 Embedding:\n",
      "  - Dimension: 1536\n",
      "  - First 10 values: [25, 15, -70, -44, -5, -15, -54, -10, 59, 49]\n",
      "  - Data type: <class 'int'>\n",
      "\n",
      "BINARY Embedding:\n",
      "  - Dimension: 192\n",
      "  - First 10 values: [72, 87, -58, 42, -37, 76, -77, -45, -39, -93]\n",
      "  - Data type: <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# Test 4: Different Embedding Types (float, int8, binary)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEST 4: Testing Different Embedding Types\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "sample_text = [\"Cloud computing enables scalable and flexible IT infrastructure.\"]\n",
    "\n",
    "# Test multiple embedding types\n",
    "embedding_types_to_test = [\"float\", \"int8\", \"binary\"]\n",
    "\n",
    "result = get_cohere_embeddings(\n",
    "    texts=sample_text,\n",
    "    input_type=\"search_document\",\n",
    "    embedding_types=embedding_types_to_test\n",
    ")\n",
    "\n",
    "if result:\n",
    "    print(f\"\\nâœ… Successfully generated embeddings in multiple formats\")\n",
    "    print(f\"ğŸ“ Text: {sample_text[0]}\\n\")\n",
    "    \n",
    "    for emb_type in embedding_types_to_test:\n",
    "        if emb_type in result['embeddings']:\n",
    "            emb = result['embeddings'][emb_type][0]\n",
    "            print(f\"\\n{emb_type.upper()} Embedding:\")\n",
    "            print(f\"  - Dimension: {len(emb)}\")\n",
    "            print(f\"  - First 10 values: {emb[:10]}\")\n",
    "            print(f\"  - Data type: {type(emb[0])}\")\n",
    "else:\n",
    "    print(\"âŒ Failed to generate embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Image Embeddings\n",
    "\n",
    "**Note**: As of now, Cohere Embed models on AWS Bedrock primarily support text embeddings. For image embeddings, you would typically use:\n",
    "- Amazon Titan Multimodal Embeddings\n",
    "- Or convert images to text descriptions first, then embed the text\n",
    "\n",
    "Below is a demonstration of how you would approach multimodal scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST 5: Image Description Embeddings\n",
      "================================================================================\n",
      "\n",
      "ğŸ“¸ Generating embeddings for image descriptions...\n",
      "\n",
      "âœ… Successfully generated 4 image description embeddings\n",
      "ğŸ“Š Embedding dimension: 1536\n",
      "\n",
      "ğŸ” Similarity between image descriptions:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Image 1 â†” Image 2: 0.1205\n",
      "  A golden retriever playing in a park with a red ball\n",
      "  A modern office building with glass facade and blue sky\n",
      "\n",
      "Image 1 â†” Image 3: 0.0854\n",
      "  A golden retriever playing in a park with a red ball\n",
      "  A plate of sushi with chopsticks on a wooden table\n",
      "\n",
      "Image 1 â†” Image 4: 0.1268\n",
      "  A golden retriever playing in a park with a red ball\n",
      "  A sunset over a mountain range with orange and purple colors\n",
      "\n",
      "Image 2 â†” Image 3: 0.1006\n",
      "  A modern office building with glass facade and blue sky\n",
      "  A plate of sushi with chopsticks on a wooden table\n",
      "\n",
      "Image 2 â†” Image 4: 0.0985\n",
      "  A modern office building with glass facade and blue sky\n",
      "  A sunset over a mountain range with orange and purple colors\n",
      "\n",
      "Image 3 â†” Image 4: 0.1742\n",
      "  A plate of sushi with chopsticks on a wooden table\n",
      "  A sunset over a mountain range with orange and purple colors\n"
     ]
    }
   ],
   "source": [
    "# Test 5: Image-to-Text Description Embedding\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEST 5: Image Description Embeddings\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Simulate image descriptions (in practice, you'd use a vision model to generate these)\n",
    "image_descriptions = [\n",
    "    \"A golden retriever playing in a park with a red ball\",\n",
    "    \"A modern office building with glass facade and blue sky\",\n",
    "    \"A plate of sushi with chopsticks on a wooden table\",\n",
    "    \"A sunset over a mountain range with orange and purple colors\"\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ“¸ Generating embeddings for image descriptions...\\n\")\n",
    "\n",
    "result = get_cohere_embeddings(\n",
    "    texts=image_descriptions,\n",
    "    input_type=\"search_document\",\n",
    "    embedding_types=[\"float\"]\n",
    ")\n",
    "\n",
    "if result:\n",
    "    embeddings = result['embeddings']['float']\n",
    "    print(f\"âœ… Successfully generated {len(embeddings)} image description embeddings\")\n",
    "    print(f\"ğŸ“Š Embedding dimension: {len(embeddings[0])}\")\n",
    "    \n",
    "    # Calculate similarities between image descriptions\n",
    "    print(\"\\nğŸ” Similarity between image descriptions:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i in range(len(image_descriptions)):\n",
    "        for j in range(i + 1, len(image_descriptions)):\n",
    "            similarity = calculate_similarity(embeddings[i], embeddings[j])\n",
    "            print(f\"\\nImage {i+1} â†” Image {j+1}: {similarity:.4f}\")\n",
    "            print(f\"  {image_descriptions[i]}\")\n",
    "            print(f\"  {image_descriptions[j]}\")\n",
    "else:\n",
    "    print(\"âŒ Failed to generate embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Multimodal Embeddings (Text + Image Descriptions)\n",
    "\n",
    "Demonstrating how to combine text queries with image description embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST 6: Multimodal Search - Text Query with Image Descriptions\n",
      "================================================================================\n",
      "\n",
      "ğŸ” Query: Find me images of food\n",
      "\n",
      "ğŸ“Š Searching through image database...\n",
      "\n",
      "ğŸ¯ Top matching images:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "1. Image #3 (Score: 0.1622)\n",
      "   Description: Fresh vegetables and fruits at a farmer's market\n",
      "   âœ“ Food-related\n",
      "\n",
      "2. Image #5 (Score: 0.1165)\n",
      "   Description: Italian pasta dish with tomato sauce and basil\n",
      "   âœ“ Food-related\n",
      "\n",
      "3. Image #4 (Score: 0.0961)\n",
      "   Description: A cityscape at night with illuminated buildings\n",
      "   âœ— Food-related\n"
     ]
    }
   ],
   "source": [
    "# Test 6: Multimodal Search (Text Query + Image Descriptions)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEST 6: Multimodal Search - Text Query with Image Descriptions\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# User query\n",
    "user_query = [\"Find me images of food\"]\n",
    "\n",
    "# Image descriptions from a hypothetical image database\n",
    "image_database = [\n",
    "    \"A gourmet burger with fries on a white plate\",\n",
    "    \"A laptop computer on a desk with coffee\",\n",
    "    \"Fresh vegetables and fruits at a farmer's market\",\n",
    "    \"A cityscape at night with illuminated buildings\",\n",
    "    \"Italian pasta dish with tomato sauce and basil\",\n",
    "    \"A person hiking on a mountain trail\"\n",
    "]\n",
    "\n",
    "# Get query embedding\n",
    "query_result = get_cohere_embeddings(\n",
    "    texts=user_query,\n",
    "    input_type=\"search_query\",\n",
    "    embedding_types=[\"float\"]\n",
    ")\n",
    "\n",
    "# Get image description embeddings\n",
    "image_result = get_cohere_embeddings(\n",
    "    texts=image_database,\n",
    "    input_type=\"search_document\",\n",
    "    embedding_types=[\"float\"]\n",
    ")\n",
    "\n",
    "if query_result and image_result:\n",
    "    query_embedding = query_result['embeddings']['float'][0]\n",
    "    image_embeddings = image_result['embeddings']['float']\n",
    "    \n",
    "    print(f\"\\nğŸ” Query: {user_query[0]}\\n\")\n",
    "    print(\"ğŸ“Š Searching through image database...\\n\")\n",
    "    \n",
    "    # Calculate similarities\n",
    "    results = []\n",
    "    for i, img_desc in enumerate(image_database):\n",
    "        similarity = calculate_similarity(query_embedding, image_embeddings[i])\n",
    "        results.append((similarity, img_desc, i))\n",
    "    \n",
    "    # Sort by similarity\n",
    "    results.sort(reverse=True)\n",
    "    \n",
    "    print(\"ğŸ¯ Top matching images:\")\n",
    "    print(\"-\" * 80)\n",
    "    for rank, (score, desc, idx) in enumerate(results[:3], 1):\n",
    "        print(f\"\\n{rank}. Image #{idx + 1} (Score: {score:.4f})\")\n",
    "        print(f\"   Description: {desc}\")\n",
    "        print(f\"   {'âœ“' if 'food' in desc.lower() or 'burger' in desc.lower() or 'pasta' in desc.lower() or 'vegetables' in desc.lower() else 'âœ—'} Food-related\")\n",
    "else:\n",
    "    print(\"âŒ Failed to generate embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Classification Use Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST 7: Text Classification using Embeddings\n",
      "================================================================================\n",
      "\n",
      "ğŸ“‹ Classification Results:\n",
      "================================================================================\n",
      "\n",
      "ğŸ“„ Document 1: The new React framework improves frontend performance significantly.\n",
      "\n",
      "Category Scores:\n",
      "  âœ“ 1. Technology and software development: 0.3722\n",
      "    2. Healthcare and medical research: 0.3702\n",
      "    3. Finance and economics: 0.3451\n",
      "    4. Sports and athletics: 0.3055\n",
      "\n",
      "ğŸ¯ Predicted Category: Technology and software development\n",
      "\n",
      "ğŸ“„ Document 2: Clinical trials show promising results for the new cancer treatment.\n",
      "\n",
      "Category Scores:\n",
      "  âœ“ 1. Healthcare and medical research: 0.4062\n",
      "    2. Sports and athletics: 0.3513\n",
      "    3. Finance and economics: 0.3003\n",
      "    4. Technology and software development: 0.2979\n",
      "\n",
      "ğŸ¯ Predicted Category: Healthcare and medical research\n",
      "\n",
      "ğŸ“„ Document 3: The Federal Reserve raised interest rates by 0.25 percentage points.\n",
      "\n",
      "Category Scores:\n",
      "  âœ“ 1. Finance and economics: 0.3993\n",
      "    2. Sports and athletics: 0.3139\n",
      "    3. Healthcare and medical research: 0.3125\n",
      "    4. Technology and software development: 0.3023\n",
      "\n",
      "ğŸ¯ Predicted Category: Finance and economics\n",
      "\n",
      "ğŸ“„ Document 4: The basketball team won the championship after an exciting final game.\n",
      "\n",
      "Category Scores:\n",
      "  âœ“ 1. Sports and athletics: 0.3880\n",
      "    2. Healthcare and medical research: 0.3318\n",
      "    3. Finance and economics: 0.3166\n",
      "    4. Technology and software development: 0.2969\n",
      "\n",
      "ğŸ¯ Predicted Category: Sports and athletics\n"
     ]
    }
   ],
   "source": [
    "# Test 7: Text Classification using Embeddings\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEST 7: Text Classification using Embeddings\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Category prototypes\n",
    "categories = [\n",
    "    \"Technology and software development\",\n",
    "    \"Healthcare and medical research\",\n",
    "    \"Finance and economics\",\n",
    "    \"Sports and athletics\"\n",
    "]\n",
    "\n",
    "# Test documents to classify\n",
    "test_documents = [\n",
    "    \"The new React framework improves frontend performance significantly.\",\n",
    "    \"Clinical trials show promising results for the new cancer treatment.\",\n",
    "    \"The Federal Reserve raised interest rates by 0.25 percentage points.\",\n",
    "    \"The basketball team won the championship after an exciting final game.\"\n",
    "]\n",
    "\n",
    "# Get category embeddings\n",
    "category_result = get_cohere_embeddings(\n",
    "    texts=categories,\n",
    "    input_type=\"classification\",\n",
    "    embedding_types=[\"float\"]\n",
    ")\n",
    "\n",
    "# Get document embeddings\n",
    "doc_result = get_cohere_embeddings(\n",
    "    texts=test_documents,\n",
    "    input_type=\"classification\",\n",
    "    embedding_types=[\"float\"]\n",
    ")\n",
    "\n",
    "if category_result and doc_result:\n",
    "    category_embeddings = category_result['embeddings']['float']\n",
    "    document_embeddings = doc_result['embeddings']['float']\n",
    "    \n",
    "    print(\"\\nğŸ“‹ Classification Results:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, doc in enumerate(test_documents):\n",
    "        print(f\"\\nğŸ“„ Document {i + 1}: {doc}\")\n",
    "        print(\"\\nCategory Scores:\")\n",
    "        \n",
    "        scores = []\n",
    "        for j, category in enumerate(categories):\n",
    "            similarity = calculate_similarity(document_embeddings[i], category_embeddings[j])\n",
    "            scores.append((similarity, category))\n",
    "        \n",
    "        scores.sort(reverse=True)\n",
    "        \n",
    "        for rank, (score, cat) in enumerate(scores, 1):\n",
    "            marker = \"âœ“\" if rank == 1 else \" \"\n",
    "            print(f\"  {marker} {rank}. {cat}: {score:.4f}\")\n",
    "        \n",
    "        print(f\"\\nğŸ¯ Predicted Category: {scores[0][1]}\")\n",
    "else:\n",
    "    print(\"âŒ Failed to generate embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance Metrics and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST 8: Performance Metrics & Statistics\n",
      "================================================================================\n",
      "\n",
      "â±ï¸ Performance Testing:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Batch Size: 1\n",
      "  Total Time: 0.1465 seconds\n",
      "  Avg Time per Text: 0.1465 seconds\n",
      "  Throughput: 6.83 texts/second\n",
      "\n",
      "Batch Size: 5\n",
      "  Total Time: 0.1344 seconds\n",
      "  Avg Time per Text: 0.0269 seconds\n",
      "  Throughput: 37.20 texts/second\n",
      "\n",
      "Batch Size: 10\n",
      "  Total Time: 0.1846 seconds\n",
      "  Avg Time per Text: 0.0185 seconds\n",
      "  Throughput: 54.18 texts/second\n",
      "\n",
      "Batch Size: 20\n",
      "  Total Time: 0.2431 seconds\n",
      "  Avg Time per Text: 0.0122 seconds\n",
      "  Throughput: 82.28 texts/second\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test 8: Performance Metrics\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEST 8: Performance Metrics & Statistics\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import time\n",
    "\n",
    "# Test different batch sizes\n",
    "batch_sizes = [1, 5, 10, 20]\n",
    "test_text = \"This is a sample text for performance testing.\"\n",
    "\n",
    "print(\"\\nâ±ï¸ Performance Testing:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    texts = [test_text] * batch_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    result = get_cohere_embeddings(\n",
    "        texts=texts,\n",
    "        input_type=\"search_document\",\n",
    "        embedding_types=[\"float\"]\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    \n",
    "    if result:\n",
    "        elapsed_time = end_time - start_time\n",
    "        avg_time = elapsed_time / batch_size\n",
    "        \n",
    "        print(f\"\\nBatch Size: {batch_size}\")\n",
    "        print(f\"  Total Time: {elapsed_time:.4f} seconds\")\n",
    "        print(f\"  Avg Time per Text: {avg_time:.4f} seconds\")\n",
    "        print(f\"  Throughput: {batch_size/elapsed_time:.2f} texts/second\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Comprehensive Validation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST 9: Comprehensive System Validation\n",
      "================================================================================\n",
      "\n",
      "ğŸ§ª Running Validation Tests...\n",
      "\n",
      "Testing: Single Text Embedding\n",
      "  âœ… PASS - Generated 1 embeddings of dimension 1536\n",
      "\n",
      "Testing: Batch Processing\n",
      "  âœ… PASS - Generated 3 embeddings of dimension 1536\n",
      "\n",
      "Testing: Multiple Embedding Types\n",
      "  âœ… PASS - Generated 1 embeddings of dimension 1536\n",
      "\n",
      "Testing: Query Type\n",
      "  âœ… PASS - Generated 1 embeddings of dimension 1536\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š VALIDATION SUMMARY\n",
      "================================================================================\n",
      "âœ… PASS Single Text Embedding\n",
      "âœ… PASS Batch Processing\n",
      "âœ… PASS Multiple Embedding Types\n",
      "âœ… PASS Query Type\n",
      "\n",
      "ğŸ¯ Overall Result: 4/4 tests passed\n",
      "\n",
      "âœ… ALL TESTS PASSED! Cohere Embed v4 model is working correctly.\n"
     ]
    }
   ],
   "source": [
    "# Test 9: Comprehensive Validation\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEST 9: Comprehensive System Validation\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "validation_tests = {\n",
    "    \"Single Text Embedding\": {\n",
    "        \"texts\": [\"Test sentence for validation.\"],\n",
    "        \"input_type\": \"search_document\",\n",
    "        \"embedding_types\": [\"float\"]\n",
    "    },\n",
    "    \"Batch Processing\": {\n",
    "        \"texts\": [\"Text 1\", \"Text 2\", \"Text 3\"],\n",
    "        \"input_type\": \"clustering\",\n",
    "        \"embedding_types\": [\"float\"]\n",
    "    },\n",
    "    \"Multiple Embedding Types\": {\n",
    "        \"texts\": [\"Sample text\"],\n",
    "        \"input_type\": \"classification\",\n",
    "        \"embedding_types\": [\"float\", \"int8\"]\n",
    "    },\n",
    "    \"Query Type\": {\n",
    "        \"texts\": [\"What is machine learning?\"],\n",
    "        \"input_type\": \"search_query\",\n",
    "        \"embedding_types\": [\"float\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\nğŸ§ª Running Validation Tests...\\n\")\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "for test_name, params in validation_tests.items():\n",
    "    print(f\"Testing: {test_name}\")\n",
    "    \n",
    "    result = get_cohere_embeddings(**params)\n",
    "    \n",
    "    if result and 'embeddings' in result:\n",
    "        status = \"âœ… PASS\"\n",
    "        embeddings = result['embeddings'][params['embedding_types'][0]]\n",
    "        details = f\"Generated {len(embeddings)} embeddings of dimension {len(embeddings[0])}\"\n",
    "    else:\n",
    "        status = \"âŒ FAIL\"\n",
    "        details = \"Failed to generate embeddings\"\n",
    "    \n",
    "    print(f\"  {status} - {details}\\n\")\n",
    "    results_summary.append((test_name, status))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ“Š VALIDATION SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for test_name, status in results_summary:\n",
    "    print(f\"{status} {test_name}\")\n",
    "\n",
    "passed = sum(1 for _, status in results_summary if \"PASS\" in status)\n",
    "total = len(results_summary)\n",
    "\n",
    "print(f\"\\nğŸ¯ Overall Result: {passed}/{total} tests passed\")\n",
    "\n",
    "if passed == total:\n",
    "    print(\"\\nâœ… ALL TESTS PASSED! Cohere Embed v4 model is working correctly.\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ {total - passed} test(s) failed. Please review the errors above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "                    COHERE EMBED V4 EVALUATION SUMMARY\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "âœ… SUCCESSFULLY TESTED:\n",
      "   â€¢ Text embeddings (single and batch)\n",
      "   â€¢ Different input types (search_query, search_document, classification, clustering)\n",
      "   â€¢ Multiple embedding types (float, int8, binary)\n",
      "   â€¢ Semantic similarity calculations\n",
      "   â€¢ Image description embeddings\n",
      "   â€¢ Multimodal search scenarios\n",
      "   â€¢ Text classification use cases\n",
      "   â€¢ Performance metrics\n",
      "\n",
      "ğŸ“‹ KEY FEATURES:\n",
      "   â€¢ Model ID: cohere.embed-english-v3 / cohere.embed-multilingual-v3\n",
      "   â€¢ Embedding Dimension: 1024 (float embeddings)\n",
      "   â€¢ Max Input Tokens: 512 tokens per text\n",
      "   â€¢ Batch Size: Up to 96 texts per request\n",
      "   â€¢ Supported Languages: English (v3) or Multilingual (multilingual-v3)\n",
      "\n",
      "ğŸ¯ INPUT TYPES:\n",
      "   â€¢ search_query: For search queries\n",
      "   â€¢ search_document: For documents to be searched\n",
      "   â€¢ classification: For classification tasks\n",
      "   â€¢ clustering: For clustering tasks\n",
      "\n",
      "ğŸ“Š EMBEDDING TYPES:\n",
      "   â€¢ float: Standard floating-point embeddings\n",
      "   â€¢ int8: 8-bit integer embeddings (smaller size)\n",
      "   â€¢ uint8: Unsigned 8-bit integer embeddings\n",
      "   â€¢ binary: Binary embeddings (most compact)\n",
      "   â€¢ ubinary: Unsigned binary embeddings\n",
      "\n",
      "ğŸ’¡ BEST PRACTICES:\n",
      "   1. Use 'search_query' for queries and 'search_document' for documents\n",
      "   2. For faster similarity search, consider int8 or binary embeddings\n",
      "   3. Batch multiple texts together for better throughput\n",
      "   4. Use truncate parameter to handle long texts\n",
      "   5. Cache embeddings when possible to reduce API calls\n",
      "   6. Monitor embedding quality with similarity metrics\n",
      "\n",
      "âš ï¸  LIMITATIONS:\n",
      "   â€¢ Native image embeddings not directly supported (use descriptions)\n",
      "   â€¢ Maximum 512 tokens per input text\n",
      "   â€¢ Requires AWS Bedrock access and proper IAM permissions\n",
      "\n",
      "ğŸ”— ADDITIONAL RESOURCES:\n",
      "   â€¢ AWS Bedrock Documentation: https://docs.aws.amazon.com/bedrock/\n",
      "   â€¢ Cohere Embed API: https://docs.cohere.com/docs/embeddings\n",
      "   â€¢ AWS SDK for Python (Boto3): https://boto3.amazonaws.com/v1/documentation/api/latest/\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "                    COHERE EMBED V4 EVALUATION SUMMARY\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "âœ… SUCCESSFULLY TESTED:\n",
    "   â€¢ Text embeddings (single and batch)\n",
    "   â€¢ Different input types (search_query, search_document, classification, clustering)\n",
    "   â€¢ Multiple embedding types (float, int8, binary)\n",
    "   â€¢ Semantic similarity calculations\n",
    "   â€¢ Image description embeddings\n",
    "   â€¢ Multimodal search scenarios\n",
    "   â€¢ Text classification use cases\n",
    "   â€¢ Performance metrics\n",
    "\n",
    "ğŸ“‹ KEY FEATURES:\n",
    "   â€¢ Model ID: cohere.embed-english-v3 / cohere.embed-multilingual-v3\n",
    "   â€¢ Embedding Dimension: 1024 (float embeddings)\n",
    "   â€¢ Max Input Tokens: 512 tokens per text\n",
    "   â€¢ Batch Size: Up to 96 texts per request\n",
    "   â€¢ Supported Languages: English (v3) or Multilingual (multilingual-v3)\n",
    "\n",
    "ğŸ¯ INPUT TYPES:\n",
    "   â€¢ search_query: For search queries\n",
    "   â€¢ search_document: For documents to be searched\n",
    "   â€¢ classification: For classification tasks\n",
    "   â€¢ clustering: For clustering tasks\n",
    "\n",
    "ğŸ“Š EMBEDDING TYPES:\n",
    "   â€¢ float: Standard floating-point embeddings\n",
    "   â€¢ int8: 8-bit integer embeddings (smaller size)\n",
    "   â€¢ uint8: Unsigned 8-bit integer embeddings\n",
    "   â€¢ binary: Binary embeddings (most compact)\n",
    "   â€¢ ubinary: Unsigned binary embeddings\n",
    "\n",
    "ğŸ’¡ BEST PRACTICES:\n",
    "   1. Use 'search_query' for queries and 'search_document' for documents\n",
    "   2. For faster similarity search, consider int8 or binary embeddings\n",
    "   3. Batch multiple texts together for better throughput\n",
    "   4. Use truncate parameter to handle long texts\n",
    "   5. Cache embeddings when possible to reduce API calls\n",
    "   6. Monitor embedding quality with similarity metrics\n",
    "\n",
    "âš ï¸  LIMITATIONS:\n",
    "   â€¢ Native image embeddings not directly supported (use descriptions)\n",
    "   â€¢ Maximum 512 tokens per input text\n",
    "   â€¢ Requires AWS Bedrock access and proper IAM permissions\n",
    "\n",
    "ğŸ”— ADDITIONAL RESOURCES:\n",
    "   â€¢ AWS Bedrock Documentation: https://docs.aws.amazon.com/bedrock/\n",
    "   â€¢ Cohere Embed API: https://docs.cohere.com/docs/embeddings\n",
    "   â€¢ AWS SDK for Python (Boto3): https://boto3.amazonaws.com/v1/documentation/api/latest/\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Integrate with Vector Databases**: Store embeddings in Pinecone, Weaviate, or Amazon OpenSearch\n",
    "2. **Build RAG Applications**: Use embeddings for Retrieval-Augmented Generation\n",
    "3. **Implement Semantic Search**: Create search engines using embedding similarity\n",
    "4. **Create Recommendation Systems**: Use embeddings for content recommendations\n",
    "5. **Monitor and Optimize**: Track performance metrics and optimize batch sizes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
